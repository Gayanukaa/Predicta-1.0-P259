{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vlAD742nxX8P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from statsmodels.tsa.deterministic import DeterministicProcess\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MEuN9z-0gR9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data_df = pd.read_csv('/content/historical_weather.csv')  # Replace with the correct file path\n",
        "submission_key = pd.read_csv('/content/submission_key.csv')\n",
        "sample_submission = pd.read_csv('/content/sample_submission.csv')"
      ],
      "metadata": {
        "id": "ua1uNVX67Uox"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BoostedHybrid:\n",
        "    def __init__(self, model_1, model_2):\n",
        "        self.model_1 = model_1\n",
        "        self.model_2 = model_2\n",
        "        self.y_columns = None\n",
        "\n",
        "    def fit(self, X_1, X_2, y):\n",
        "        self.model_1.fit(X_1, y)\n",
        "        y_fit = pd.Series(self.model_1.predict(X_1), index=y.index)\n",
        "        y_resid = y - y_fit\n",
        "        self.model_2.fit(X_2, y_resid)\n",
        "        self.y_fit = y_fit\n",
        "        self.y_resid = y_resid\n",
        "\n",
        "    def predict(self, X_1, X_2):\n",
        "        y_pred = pd.Series(self.model_1.predict(X_1), index=X_1.index)\n",
        "        y_pred += self.model_2.predict(X_2)\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "vqwlytjh7ZJM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess historical weather data\n",
        "data_df['avg_temp_c'] = data_df.apply(\n",
        "    lambda row: (row['min_temp_c'] + row['max_temp_c']) / 2\n",
        "    if pd.isna(row.get('avg_temp_c', None)) and not pd.isna(row['min_temp_c']) and not pd.isna(row['max_temp_c']) # Use row.get() to avoid KeyError if 'avg_temp_c' doesn't exist\n",
        "    else row.get('avg_temp_c', None), # Use row.get() to handle potential missing 'avg_temp_c'\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Remove rows where avg_temp_c is still NaN\n",
        "data_df = data_df.dropna(subset=['avg_temp_c'])"
      ],
      "metadata": {
        "id": "Yq3cI5AZ8OMh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical 'city_id' column\n",
        "label_encoder = LabelEncoder()\n",
        "data_df.loc[:, 'city_id'] = label_encoder.fit_transform(data_df['city_id'])\n",
        "\n",
        "# Convert 'date' column to datetime and extract useful features\n",
        "data_df['date'] = pd.to_datetime(data_df['date'], format='%Y-%m-%d')\n",
        "\n",
        "# Drop the original 'date' column\n",
        "data_df = data_df.drop(columns=['date'])\n",
        "\n"
      ],
      "metadata": {
        "id": "BDmP4oSR8RK6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data_df' is your preprocessed DataFrame\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define your target variable (assuming 'avg_temp_c' is your target)\n",
        "y = data_df['avg_temp_c']\n",
        "\n",
        "# Define features for model 1 and model 2 (replace with your actual features)\n",
        "features_1 = ['city_id']\n",
        "features_2 = ['min_temp_c', 'max_temp_c']\n",
        "X_1 = data_df[features_1]\n",
        "X_2 = data_df[features_2]\n",
        "\n",
        "# Split the data into training and validation sets (adjust test_size as needed)\n",
        "X_1_train, X_1_val, X_2_train, X_2_val, y_train, y_val = train_test_split(\n",
        "    X_1, X_2, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = BoostedHybrid(\n",
        "    model_1=LinearRegression(),\n",
        "    model_2=XGBRegressor(),\n",
        ")\n",
        "\n",
        "model.fit(X_1_train, X_2_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = model.predict(X_1_val, X_2_val)\n",
        "y_pred = y_pred.clip(0.0)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "print(f'RMSE: {rmse}')\n"
      ],
      "metadata": {
        "id": "eLpaxTyC8XzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707baa92-0f3a-4e40-b3ea-291530a1ca7e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2.3753783285804566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_data = submission_key.copy()\n",
        "submission_data['city_id'] = label_encoder.transform(submission_data['city_id'])\n",
        "submission_data['date'] = pd.to_datetime(submission_data['date'], format='%Y-%m-%d') # Change the format specifier to match the actual date format in your data.\n",
        "\n",
        "# Create features from date for submission data\n",
        "submission_data['year'] = submission_data['date'].dt.year\n",
        "submission_data['month'] = submission_data['date'].dt.month\n",
        "submission_data['day'] = submission_data['date'].dt.day\n",
        "\n",
        "# Drop the original 'date' column\n",
        "submission_data = submission_data.drop(columns=['date'])\n",
        "\n",
        "# X_1 and X_2 for submission\n",
        "# dp_sub = DeterministicProcess(index=submission_data.index, order=1) # Commenting out this line\n",
        "# X_1_sub = dp_sub.in_sample() # Commenting out this line\n",
        "X_1_sub = submission_data[['city_id']] # Selecting the 'city_id' column for X_1_sub\n",
        "\n",
        "X_2_sub = submission_data.drop(columns=['submission_ID'])  # Drop the submission_ID\n",
        "X_2_sub = X_2_sub.astype(float)"
      ],
      "metadata": {
        "id": "TiLVD0el9baG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-introduce date processing for submission data\n",
        "submission_data['date'] = pd.to_datetime(submission_data['date'], format='%Y-%m-%d')\n",
        "\n",
        "# ... (Your existing code to derive min_temp_c and max_temp_c for submission_data,\n",
        "#      which might involve using a model or some other logic)\n",
        "\n",
        "# X_1 and X_2 for submission\n",
        "X_1_sub = submission_data[['city_id']]\n",
        "\n",
        "# Include only 'min_temp_c', 'max_temp_c' in X_2_sub\n",
        "X_2_sub = submission_data[['min_temp_c', 'max_temp_c']]\n",
        "X_2_sub = X_2_sub.astype(float)"
      ],
      "metadata": {
        "id": "yHweHDnI9ecY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ee505df5-c59e-4fe8-b76d-84266d4f1f99"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['min_temp_c', 'max_temp_c'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e0f46ceefe90>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Include only 'min_temp_c', 'max_temp_c' in X_2_sub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_2_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_temp_c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_temp_c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mX_2_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_2_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5937\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5938\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['min_temp_c', 'max_temp_c'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    }
  ]
}